{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement layers as a python function\n",
    "**1. Inner Product Forward Propagation :** <br/>\n",
    ">The input unit is composed of 28 pixel by 28 pixel image in grey scale intensity(between 0 and 1). Here ｗe have 60000 input units.\n",
    "Take each input then multiply them by the weight,sum all of products of all connections to the nodes.<br/>\n",
    "**[60000,748] dot [748,15] ==> [60000,15]**<br/>\n",
    "Here we will add bias b to get the desired function<br/>\n",
    "<br/>\n",
    "\n",
    "**2. Sigmoid Forward Propagation :**<br/>\n",
    ">Sum of the Inner product For_prop is passed through the sigmoid function<br/>\n",
    "<img src=\"https://user-images.githubusercontent.com/20013955/31339204-a4880a12-ad34-11e7-8ccb-137ef5297b2f.png",width=150,height=150>\n",
    "<img src=\"../Lab1/figure/sigmoid.png\",width=150,height=150>\n",
    ">It gives the activation of each of the units in the hidden layer to make the output result become nonlinear<br/>\n",
    "The gradient of the sigmoid function vanishes as we increase or decrease x<br/>\n",
    "<img src=\"figure/figure2.png\",width=250,height=250>\n",
    "<br/>\n",
    "\n",
    "**3. Rectified Forward Propagation :**<br/>\n",
    ">It is an another activation function.If sum of the Inner product less than zero then output zero. If sum of the Inner product more than zero then output one\n",
    "<img src=\"figure/relu.png\",width=200,height=200>\n",
    ">the gradient of the ReL function doesn't vanish as we increase x\n",
    "<img src=\"figure/figure1.png\",width=250,height=250>\n",
    "<br/>\n",
    "\n",
    "**4. Softmax Forward Propagation :** <br/>\n",
    ">Softmax function can highlights the largest input and suppresses all the other smaller ones\n",
    "<img src=\"figure/softmax.png\",width=120,height=120>\n",
    ">**for example : softargmax( [3,5,0] ) ≈ [0.12,0.88,0]**\n",
    " \n",
    "**5. Inner Product Backward Propagation :** <br/>\n",
    "Backward Pass calculate the gradient of loss，for updating parameter。This pass goes from top to bottom\n",
    ">Do the partial derivative to get dEdW dEdb dEdx which means the changing value affects the total error\n",
    "\n",
    "**6.  Sigmoid Backward Propagation :**<br/>\n",
    "<img src=\"figure/sigmoid2.png\",width=300,height=300>\n",
    "<img src=\"figure/sigmoid1.png\",width=300,height=300>\n",
    "**7.  Rectified Backward Propagation :**<br/>\n",
    ">if input x > 0 then it will continue propagating, else it will stop\n",
    ">**dEdy[x<=0] = 0**\n",
    "\n",
    "**8.  Softmax Backward Propagation :**<br/>\n",
    ">We need to let our ouput result get closer to the training label, so we can use softmax backward propagation to find out the bias between result and label.<br/>\n",
    ">>**result = [0.3, 0.2 0.5] minus label = [0, 1, 0]** <br/>\n",
    ">>**==> softmax_backprop = [0.3, -0.8, 0.5] ** \n",
    ">if the bias is small ,then it means it get closer to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def InnerProduct_ForProp(x,W,b):\n",
    "    y = np.dot(x,W)+b\n",
    "    return y\n",
    "\n",
    "\n",
    "def InnerProduct_BackProp(dEdy,x,W,b):\n",
    "\n",
    "    \"\"\"\n",
    "    dEdx = W*np.array([dEdy]).T\n",
    "    dEdx = dEdx.T\n",
    "    \"\"\"\n",
    "    dEdb = dEdy*b\n",
    "    \n",
    "    (n,m) = dEdb.shape\n",
    "    dEdb = np.sum(dEdb) / n\n",
    "    \"\"\"\n",
    "    (n,m) = dEdy.shape\n",
    "    dEdW = x.T*dEdy / n\n",
    "    \"\"\"\n",
    "    \n",
    "    m = x.shape[1]\n",
    "    dEdW = 1./m * np.dot(x.T,dEdy)\n",
    "    #dEdb = 1./m * np.sum(dEdy, axis = 1, keepdims = True)\n",
    "    dEdx = np.dot(dEdy,W.T)\n",
    "    \n",
    "    return dEdx,dEdW,dEdb\n",
    "\n",
    "def Softmax_ForProp(x):\n",
    "    # avoid overflow\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    y = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    return y\n",
    "\n",
    "\n",
    "def Softmax_BackProp(y,t):\n",
    "    dEdx = y - t;\n",
    "    return dEdx\n",
    "\n",
    "def Sigmoid_ForProp(x):\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y\n",
    "\n",
    "def Sigmoid_BackProp(dEdy,x):\n",
    "    #s = 1 / (1 + np.exp(-x))\n",
    "    dEdx = dEdy * x * (1-x)\n",
    "    return dEdx\n",
    "\n",
    "def Rectified_ForProp(x):\n",
    "    y = np.maximum(0, x)\n",
    "    return y\n",
    "\n",
    "def Rectified_BackProp(dEdy,x):\n",
    "    dEdx = np.array(dEdy, copy=True) # just converting dEdx to a correct object.\n",
    "    # When x <= 0, you should set dEdx to 0 as well. \n",
    "    dEdx[x <= 0] = 0\n",
    "    return dEdx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### { Load in the data } \n",
    "The problem we are trying to solve here is to classify grayscale images of handwritten digits (28 pixels by 28 pixels), into their 10 categories (0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "#load MNIST data\n",
    "mndata = MNIST('./data',return_type='numpy')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### { Data Preprocessing }\n",
    "**Image set part:**\n",
    ">Separating the train_image into 7:3. Seven for training and three for validating.<br/>\n",
    ">Beforeｉseparate it, i do **normalization** to make the value of data set in range (0,1) by dividing all of them in **255**\n",
    "\n",
    "** Label set part:**\n",
    ">Because each output result of images will be 10 values set, so we need to do **one hot** to make the label become ten values<br/>\n",
    "**for example: label = 4 => do one hot => [0,0,0,0,1,0,0,0,0,0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(42000, 10)\n",
      "(18000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Separate train_image,train_labels into training and validating\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "def one_hot(x):\n",
    "    #print(x)\n",
    "    ofm = np.zeros(10)\n",
    "    ofm[x] = 1\n",
    "    #print np.array([ofm])\n",
    "    return np.array([ofm])\n",
    "\n",
    "\n",
    "train_images = train_images/255\n",
    "test_images = test_images/255\n",
    " \n",
    "\n",
    "training_image = train_images[:int(len(train_images)*0.7)]\n",
    "validating_image = train_images[int(len(train_images)*0.7):]\n",
    "testing_image = test_images[0:10000]\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "training_label =  np.empty((0,10),int)\n",
    "validating_label =  np.empty((0,10),int)\n",
    "testing_label =  np.empty((0,10),int)\n",
    "\n",
    "\n",
    "print(train_labels.shape)\n",
    "for i in range(0, int(len(train_images)*0.7)):\n",
    "    training_label = np.append(training_label,one_hot(train_labels[i]),axis=0)\n",
    "for i in range(42000, 60000):\n",
    "    validating_label = np.append(validating_label,one_hot(train_labels[i]),axis=0)\n",
    "for i in range(0, 10000):\n",
    "     testing_label = np.append(testing_label,one_hot(test_labels[i]),axis=0)\n",
    "print (training_label.shape)\n",
    "print (validating_label.shape)\n",
    "print (testing_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### { Define the parameters }\n",
    "**learning rate : 0.01**<br/>\n",
    "**iteration : 5000**<br/>\n",
    "**decay_rate : 0.8**<br/>\n",
    "**Random the weights & biases at first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "eta = 0.001       #learning rate\n",
    "size0 = 784   #size of layer 1 (input layer)\n",
    "size1 = 100   #size of layer 2 (1st hidden layer)\n",
    "size2 = 50   #size of layer 3 (2nd hidden layer)\n",
    "size3 = 25   #size of layer 4 (3rd hidden layer)\n",
    "size4 = 10    #size of layer 5 (output layer)\n",
    "epoch = 25    #epoch for training \n",
    "iteration = 5001\n",
    "decay_rate = 0.9\n",
    "params = {}\n",
    "params['W1'] = np.random.randn(size0,size1)\n",
    "params['b1'] = np.zeros(size1)\n",
    "params['W2'] = np.random.randn(size1,size2)\n",
    "params['b2'] = np.zeros(size2)\n",
    "params['W3'] = np.random.randn(size2,size3)\n",
    "params['b3'] = np.zeros(size3)\n",
    "params['W4'] = np.random.randn(size3,size4)\n",
    "params['b4'] = np.zeros(size4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model   { 3-layer with 2 relu and 1 sigmoid }\n",
    "**1. Forward-propagation : <br/>\n",
    "Inner Product - Relu - Inner Product - Relu- Inner Product - Sigmoid - Inner Product - Softmax** <br/>\n",
    ">*Input* : training image , weight and bias <br/>\n",
    "*Output* : (42000,10) array. Included 42000 image. Each image contains 10 value which represents the confident score about digit number 0-9\n",
    "<img src=\"figure/nn.png\",width=450,height=450>\n",
    "\n",
    "**2. Backward-propagation : <br/>\n",
    "Softmax_back - Inner Product_back - Sigmoid_back - Inner Product_back - Relu_back - Inner Product_back - Relu_back - Inner Product_back**<br/>\n",
    ">Consider w1. We want to know how much a change in w1 affects the total error<img src=\"figure/dedw.png\",width=300,height=300>\n",
    "\n",
    "**3. Parameter updating**\n",
    ">To decrease the error, we then subtract this value from the current weight (optionally multiplied by some learning rate, eta, which we’ll set to 0.01):\n",
    ">>W1 = W1 - eta * dEW1\n",
    "\n",
    "**4. Do cross validation**\n",
    ">Do the forward propagation again and get the output of \"train_image prediction\", \"valid_image prediction\", \"test_image prediction\"<br/>\n",
    "\n",
    "**5. Get Accuracy**\n",
    ">Comparing the value of them with their label set which we do the one hot before to get the final accuracy\n",
    ">Here i use **zip** function together two lists \"image\" & \"label\" and find their max value's index by using **argmax**<br/>\n",
    "In valid image and valid label,containing 18000 elements each, the result has 18000 elements. Each element is a two-tuple (a,b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:40: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round : 0 | Train Accuracy : 10.250000\n",
      "Round : 0 | Valid Accuracy : 9.983333\n",
      "Round : 0 | Test Accuracy : 10.200000\n",
      "-----------------------------------------\n",
      "Round : 50 | Train Accuracy : 47.490476\n",
      "Round : 50 | Valid Accuracy : 48.161111\n",
      "Round : 50 | Test Accuracy : 48.370000\n",
      "-----------------------------------------\n",
      "Round : 100 | Train Accuracy : 55.871429\n",
      "Round : 100 | Valid Accuracy : 56.127778\n",
      "Round : 100 | Test Accuracy : 56.520000\n",
      "-----------------------------------------\n",
      "Round : 150 | Train Accuracy : 61.280952\n",
      "Round : 150 | Valid Accuracy : 61.222222\n",
      "Round : 150 | Test Accuracy : 61.670000\n",
      "-----------------------------------------\n",
      "Round : 200 | Train Accuracy : 65.671429\n",
      "Round : 200 | Valid Accuracy : 64.983333\n",
      "Round : 200 | Test Accuracy : 65.630000\n",
      "-----------------------------------------\n",
      "Round : 250 | Train Accuracy : 68.038095\n",
      "Round : 250 | Valid Accuracy : 67.011111\n",
      "Round : 250 | Test Accuracy : 68.200000\n",
      "-----------------------------------------\n",
      "Round : 300 | Train Accuracy : 69.911905\n",
      "Round : 300 | Valid Accuracy : 69.172222\n",
      "Round : 300 | Test Accuracy : 70.250000\n",
      "-----------------------------------------\n",
      "Round : 350 | Train Accuracy : 71.642857\n",
      "Round : 350 | Valid Accuracy : 70.694444\n",
      "Round : 350 | Test Accuracy : 71.570000\n",
      "-----------------------------------------\n",
      "Round : 400 | Train Accuracy : 73.033333\n",
      "Round : 400 | Valid Accuracy : 72.088889\n",
      "Round : 400 | Test Accuracy : 72.940000\n",
      "-----------------------------------------\n",
      "Round : 450 | Train Accuracy : 73.980952\n",
      "Round : 450 | Valid Accuracy : 73.244444\n",
      "Round : 450 | Test Accuracy : 73.770000\n",
      "-----------------------------------------\n",
      "Round : 500 | Train Accuracy : 75.042857\n",
      "Round : 500 | Valid Accuracy : 74.177778\n",
      "Round : 500 | Test Accuracy : 74.670000\n",
      "-----------------------------------------\n",
      "Round : 550 | Train Accuracy : 75.661905\n",
      "Round : 550 | Valid Accuracy : 74.822222\n",
      "Round : 550 | Test Accuracy : 75.540000\n",
      "-----------------------------------------\n",
      "Round : 600 | Train Accuracy : 76.269048\n",
      "Round : 600 | Valid Accuracy : 75.422222\n",
      "Round : 600 | Test Accuracy : 76.200000\n",
      "-----------------------------------------\n",
      "Round : 650 | Train Accuracy : 76.938095\n",
      "Round : 650 | Valid Accuracy : 76.327778\n",
      "Round : 650 | Test Accuracy : 76.580000\n",
      "-----------------------------------------\n",
      "Round : 700 | Train Accuracy : 77.450000\n",
      "Round : 700 | Valid Accuracy : 76.588889\n",
      "Round : 700 | Test Accuracy : 76.890000\n",
      "-----------------------------------------\n",
      "Round : 750 | Train Accuracy : 78.047619\n",
      "Round : 750 | Valid Accuracy : 77.161111\n",
      "Round : 750 | Test Accuracy : 77.710000\n",
      "-----------------------------------------\n",
      "Round : 800 | Train Accuracy : 78.530952\n",
      "Round : 800 | Valid Accuracy : 77.661111\n",
      "Round : 800 | Test Accuracy : 77.920000\n",
      "-----------------------------------------\n",
      "Round : 850 | Train Accuracy : 78.933333\n",
      "Round : 850 | Valid Accuracy : 77.883333\n",
      "Round : 850 | Test Accuracy : 78.200000\n",
      "-----------------------------------------\n",
      "Round : 900 | Train Accuracy : 79.285714\n",
      "Round : 900 | Valid Accuracy : 78.216667\n",
      "Round : 900 | Test Accuracy : 78.450000\n",
      "-----------------------------------------\n",
      "Round : 950 | Train Accuracy : 79.445238\n",
      "Round : 950 | Valid Accuracy : 78.550000\n",
      "Round : 950 | Test Accuracy : 78.880000\n",
      "-----------------------------------------\n",
      "Round : 1000 | Train Accuracy : 80.090476\n",
      "Round : 1000 | Valid Accuracy : 78.833333\n",
      "Round : 1000 | Test Accuracy : 79.310000\n",
      "-----------------------------------------\n",
      "decay!!...........\n",
      "Round : 1050 | Train Accuracy : 80.311905\n",
      "Round : 1050 | Valid Accuracy : 79.200000\n",
      "Round : 1050 | Test Accuracy : 79.420000\n",
      "-----------------------------------------\n",
      "Round : 1100 | Train Accuracy : 80.859524\n",
      "Round : 1100 | Valid Accuracy : 79.361111\n",
      "Round : 1100 | Test Accuracy : 79.820000\n",
      "-----------------------------------------\n",
      "Round : 1150 | Train Accuracy : 80.657143\n",
      "Round : 1150 | Valid Accuracy : 79.616667\n",
      "Round : 1150 | Test Accuracy : 79.970000\n",
      "-----------------------------------------\n",
      "Round : 1200 | Train Accuracy : 81.321429\n",
      "Round : 1200 | Valid Accuracy : 79.916667\n",
      "Round : 1200 | Test Accuracy : 80.270000\n",
      "-----------------------------------------\n",
      "Round : 1250 | Train Accuracy : 81.514286\n",
      "Round : 1250 | Valid Accuracy : 79.988889\n",
      "Round : 1250 | Test Accuracy : 80.370000\n",
      "-----------------------------------------\n",
      "Round : 1300 | Train Accuracy : 81.669048\n",
      "Round : 1300 | Valid Accuracy : 80.283333\n",
      "Round : 1300 | Test Accuracy : 80.560000\n",
      "-----------------------------------------\n",
      "Round : 1350 | Train Accuracy : 81.888095\n",
      "Round : 1350 | Valid Accuracy : 80.316667\n",
      "Round : 1350 | Test Accuracy : 80.740000\n",
      "-----------------------------------------\n",
      "Round : 1400 | Train Accuracy : 82.030952\n",
      "Round : 1400 | Valid Accuracy : 80.511111\n",
      "Round : 1400 | Test Accuracy : 80.950000\n",
      "-----------------------------------------\n",
      "Round : 1450 | Train Accuracy : 82.242857\n",
      "Round : 1450 | Valid Accuracy : 80.777778\n",
      "Round : 1450 | Test Accuracy : 81.290000\n",
      "-----------------------------------------\n",
      "Round : 1500 | Train Accuracy : 82.523810\n",
      "Round : 1500 | Valid Accuracy : 80.877778\n",
      "Round : 1500 | Test Accuracy : 81.480000\n",
      "-----------------------------------------\n",
      "Round : 1550 | Train Accuracy : 82.626190\n",
      "Round : 1550 | Valid Accuracy : 81.022222\n",
      "Round : 1550 | Test Accuracy : 81.660000\n",
      "-----------------------------------------\n",
      "Round : 1600 | Train Accuracy : 82.814286\n",
      "Round : 1600 | Valid Accuracy : 81.222222\n",
      "Round : 1600 | Test Accuracy : 81.820000\n",
      "-----------------------------------------\n",
      "Round : 1650 | Train Accuracy : 83.033333\n",
      "Round : 1650 | Valid Accuracy : 81.383333\n",
      "Round : 1650 | Test Accuracy : 81.780000\n",
      "-----------------------------------------\n",
      "Round : 1700 | Train Accuracy : 83.309524\n",
      "Round : 1700 | Valid Accuracy : 81.450000\n",
      "Round : 1700 | Test Accuracy : 82.060000\n",
      "-----------------------------------------\n",
      "Round : 1750 | Train Accuracy : 83.347619\n",
      "Round : 1750 | Valid Accuracy : 81.705556\n",
      "Round : 1750 | Test Accuracy : 82.130000\n",
      "-----------------------------------------\n",
      "Round : 1800 | Train Accuracy : 83.707143\n",
      "Round : 1800 | Valid Accuracy : 81.711111\n",
      "Round : 1800 | Test Accuracy : 82.370000\n",
      "-----------------------------------------\n",
      "Round : 1850 | Train Accuracy : 83.900000\n",
      "Round : 1850 | Valid Accuracy : 81.827778\n",
      "Round : 1850 | Test Accuracy : 82.470000\n",
      "-----------------------------------------\n",
      "Round : 1900 | Train Accuracy : 83.554762\n",
      "Round : 1900 | Valid Accuracy : 81.822222\n",
      "Round : 1900 | Test Accuracy : 82.780000\n",
      "-----------------------------------------\n",
      "Round : 1950 | Train Accuracy : 83.992857\n",
      "Round : 1950 | Valid Accuracy : 82.016667\n",
      "Round : 1950 | Test Accuracy : 82.640000\n",
      "-----------------------------------------\n",
      "Round : 2000 | Train Accuracy : 83.947619\n",
      "Round : 2000 | Valid Accuracy : 82.072222\n",
      "Round : 2000 | Test Accuracy : 82.710000\n",
      "-----------------------------------------\n",
      "decay!!...........\n",
      "Round : 2050 | Train Accuracy : 84.526190\n",
      "Round : 2050 | Valid Accuracy : 82.227778\n",
      "Round : 2050 | Test Accuracy : 82.940000\n",
      "-----------------------------------------\n",
      "Round : 2100 | Train Accuracy : 84.254762\n",
      "Round : 2100 | Valid Accuracy : 82.255556\n",
      "Round : 2100 | Test Accuracy : 83.220000\n",
      "-----------------------------------------\n",
      "Round : 2150 | Train Accuracy : 84.485714\n",
      "Round : 2150 | Valid Accuracy : 82.383333\n",
      "Round : 2150 | Test Accuracy : 83.120000\n",
      "-----------------------------------------\n",
      "Round : 2200 | Train Accuracy : 84.497619\n",
      "Round : 2200 | Valid Accuracy : 82.366667\n",
      "Round : 2200 | Test Accuracy : 83.150000\n",
      "-----------------------------------------\n",
      "Round : 2250 | Train Accuracy : 84.638095\n",
      "Round : 2250 | Valid Accuracy : 82.555556\n",
      "Round : 2250 | Test Accuracy : 83.130000\n",
      "-----------------------------------------\n",
      "Round : 2300 | Train Accuracy : 84.607143\n",
      "Round : 2300 | Valid Accuracy : 82.483333\n",
      "Round : 2300 | Test Accuracy : 83.300000\n",
      "-----------------------------------------\n",
      "Round : 2350 | Train Accuracy : 84.785714\n",
      "Round : 2350 | Valid Accuracy : 82.611111\n",
      "Round : 2350 | Test Accuracy : 83.220000\n",
      "-----------------------------------------\n",
      "Round : 2400 | Train Accuracy : 84.954762\n",
      "Round : 2400 | Valid Accuracy : 82.672222\n",
      "Round : 2400 | Test Accuracy : 83.360000\n",
      "-----------------------------------------\n",
      "Round : 2450 | Train Accuracy : 85.104762\n",
      "Round : 2450 | Valid Accuracy : 82.711111\n",
      "Round : 2450 | Test Accuracy : 83.280000\n",
      "-----------------------------------------\n",
      "Round : 2500 | Train Accuracy : 84.861905\n",
      "Round : 2500 | Valid Accuracy : 82.622222\n",
      "Round : 2500 | Test Accuracy : 83.380000\n",
      "-----------------------------------------\n",
      "Round : 2550 | Train Accuracy : 85.169048\n",
      "Round : 2550 | Valid Accuracy : 82.766667\n",
      "Round : 2550 | Test Accuracy : 83.480000\n",
      "-----------------------------------------\n",
      "Round : 2600 | Train Accuracy : 85.092857\n",
      "Round : 2600 | Valid Accuracy : 82.833333\n",
      "Round : 2600 | Test Accuracy : 83.470000\n",
      "-----------------------------------------\n",
      "Round : 2650 | Train Accuracy : 85.185714\n",
      "Round : 2650 | Valid Accuracy : 82.861111\n",
      "Round : 2650 | Test Accuracy : 83.580000\n",
      "-----------------------------------------\n",
      "Round : 2700 | Train Accuracy : 85.216667\n",
      "Round : 2700 | Valid Accuracy : 82.883333\n",
      "Round : 2700 | Test Accuracy : 83.640000\n",
      "-----------------------------------------\n",
      "Round : 2750 | Train Accuracy : 85.342857\n",
      "Round : 2750 | Valid Accuracy : 82.866667\n",
      "Round : 2750 | Test Accuracy : 83.750000\n",
      "-----------------------------------------\n",
      "Round : 2800 | Train Accuracy : 85.514286\n",
      "Round : 2800 | Valid Accuracy : 83.022222\n",
      "Round : 2800 | Test Accuracy : 83.760000\n",
      "-----------------------------------------\n",
      "Round : 2850 | Train Accuracy : 85.519048\n",
      "Round : 2850 | Valid Accuracy : 83.000000\n",
      "Round : 2850 | Test Accuracy : 83.700000\n",
      "-----------------------------------------\n",
      "Round : 2900 | Train Accuracy : 85.364286\n",
      "Round : 2900 | Valid Accuracy : 83.105556\n",
      "Round : 2900 | Test Accuracy : 83.920000\n",
      "-----------------------------------------\n",
      "Round : 2950 | Train Accuracy : 85.135714\n",
      "Round : 2950 | Valid Accuracy : 83.033333\n",
      "Round : 2950 | Test Accuracy : 83.860000\n",
      "-----------------------------------------\n",
      "Round : 3000 | Train Accuracy : 85.447619\n",
      "Round : 3000 | Valid Accuracy : 82.966667\n",
      "Round : 3000 | Test Accuracy : 83.790000\n",
      "-----------------------------------------\n",
      "decay!!...........\n",
      "Round : 3050 | Train Accuracy : 85.921429\n",
      "Round : 3050 | Valid Accuracy : 83.172222\n",
      "Round : 3050 | Test Accuracy : 84.030000\n",
      "-----------------------------------------\n",
      "Round : 3100 | Train Accuracy : 85.930952\n",
      "Round : 3100 | Valid Accuracy : 83.166667\n",
      "Round : 3100 | Test Accuracy : 84.120000\n",
      "-----------------------------------------\n",
      "Round : 3150 | Train Accuracy : 86.014286\n",
      "Round : 3150 | Valid Accuracy : 83.155556\n",
      "Round : 3150 | Test Accuracy : 84.190000\n",
      "-----------------------------------------\n",
      "Round : 3200 | Train Accuracy : 86.061905\n",
      "Round : 3200 | Valid Accuracy : 83.311111\n",
      "Round : 3200 | Test Accuracy : 84.100000\n",
      "-----------------------------------------\n",
      "Round : 3250 | Train Accuracy : 85.804762\n",
      "Round : 3250 | Valid Accuracy : 83.183333\n",
      "Round : 3250 | Test Accuracy : 84.140000\n",
      "-----------------------------------------\n",
      "Round : 3300 | Train Accuracy : 86.040476\n",
      "Round : 3300 | Valid Accuracy : 83.261111\n",
      "Round : 3300 | Test Accuracy : 84.070000\n",
      "-----------------------------------------\n",
      "Round : 3350 | Train Accuracy : 85.819048\n",
      "Round : 3350 | Valid Accuracy : 83.300000\n",
      "Round : 3350 | Test Accuracy : 84.180000\n",
      "-----------------------------------------\n",
      "Round : 3400 | Train Accuracy : 86.028571\n",
      "Round : 3400 | Valid Accuracy : 83.272222\n",
      "Round : 3400 | Test Accuracy : 84.060000\n",
      "-----------------------------------------\n",
      "Round : 3450 | Train Accuracy : 86.057143\n",
      "Round : 3450 | Valid Accuracy : 83.305556\n",
      "Round : 3450 | Test Accuracy : 84.200000\n",
      "-----------------------------------------\n",
      "Round : 3500 | Train Accuracy : 86.176190\n",
      "Round : 3500 | Valid Accuracy : 83.322222\n",
      "Round : 3500 | Test Accuracy : 84.420000\n",
      "-----------------------------------------\n",
      "Round : 3550 | Train Accuracy : 86.307143\n",
      "Round : 3550 | Valid Accuracy : 83.444444\n",
      "Round : 3550 | Test Accuracy : 84.190000\n",
      "-----------------------------------------\n",
      "Round : 3600 | Train Accuracy : 86.388095\n",
      "Round : 3600 | Valid Accuracy : 83.438889\n",
      "Round : 3600 | Test Accuracy : 84.270000\n",
      "-----------------------------------------\n",
      "Round : 3650 | Train Accuracy : 86.442857\n",
      "Round : 3650 | Valid Accuracy : 83.466667\n",
      "Round : 3650 | Test Accuracy : 84.340000\n",
      "-----------------------------------------\n",
      "Round : 3700 | Train Accuracy : 86.076190\n",
      "Round : 3700 | Valid Accuracy : 83.400000\n",
      "Round : 3700 | Test Accuracy : 84.430000\n",
      "-----------------------------------------\n",
      "Round : 3750 | Train Accuracy : 86.478571\n",
      "Round : 3750 | Valid Accuracy : 83.488889\n",
      "Round : 3750 | Test Accuracy : 84.500000\n",
      "-----------------------------------------\n",
      "Round : 3800 | Train Accuracy : 86.323810\n",
      "Round : 3800 | Valid Accuracy : 83.511111\n",
      "Round : 3800 | Test Accuracy : 84.450000\n",
      "-----------------------------------------\n",
      "Round : 3850 | Train Accuracy : 86.378571\n",
      "Round : 3850 | Valid Accuracy : 83.561111\n",
      "Round : 3850 | Test Accuracy : 84.400000\n",
      "-----------------------------------------\n",
      "Round : 3900 | Train Accuracy : 86.652381\n",
      "Round : 3900 | Valid Accuracy : 83.650000\n",
      "Round : 3900 | Test Accuracy : 84.380000\n",
      "-----------------------------------------\n",
      "Round : 3950 | Train Accuracy : 86.542857\n",
      "Round : 3950 | Valid Accuracy : 83.683333\n",
      "Round : 3950 | Test Accuracy : 84.360000\n",
      "-----------------------------------------\n",
      "Round : 4000 | Train Accuracy : 86.664286\n",
      "Round : 4000 | Valid Accuracy : 83.572222\n",
      "Round : 4000 | Test Accuracy : 84.470000\n",
      "-----------------------------------------\n",
      "decay!!...........\n",
      "Round : 4050 | Train Accuracy : 86.814286\n",
      "Round : 4050 | Valid Accuracy : 83.633333\n",
      "Round : 4050 | Test Accuracy : 84.460000\n",
      "-----------------------------------------\n",
      "Round : 4100 | Train Accuracy : 86.788095\n",
      "Round : 4100 | Valid Accuracy : 83.594444\n",
      "Round : 4100 | Test Accuracy : 84.500000\n",
      "-----------------------------------------\n",
      "Round : 4150 | Train Accuracy : 86.821429\n",
      "Round : 4150 | Valid Accuracy : 83.627778\n",
      "Round : 4150 | Test Accuracy : 84.400000\n",
      "-----------------------------------------\n",
      "Round : 4200 | Train Accuracy : 86.766667\n",
      "Round : 4200 | Valid Accuracy : 83.655556\n",
      "Round : 4200 | Test Accuracy : 84.330000\n",
      "-----------------------------------------\n",
      "Round : 4250 | Train Accuracy : 86.757143\n",
      "Round : 4250 | Valid Accuracy : 83.733333\n",
      "Round : 4250 | Test Accuracy : 84.410000\n",
      "-----------------------------------------\n",
      "Round : 4300 | Train Accuracy : 86.766667\n",
      "Round : 4300 | Valid Accuracy : 83.650000\n",
      "Round : 4300 | Test Accuracy : 84.440000\n",
      "-----------------------------------------\n",
      "Round : 4350 | Train Accuracy : 86.800000\n",
      "Round : 4350 | Valid Accuracy : 83.677778\n",
      "Round : 4350 | Test Accuracy : 84.410000\n",
      "-----------------------------------------\n",
      "Round : 4400 | Train Accuracy : 86.830952\n",
      "Round : 4400 | Valid Accuracy : 83.666667\n",
      "Round : 4400 | Test Accuracy : 84.330000\n",
      "-----------------------------------------\n",
      "Round : 4450 | Train Accuracy : 86.828571\n",
      "Round : 4450 | Valid Accuracy : 83.711111\n",
      "Round : 4450 | Test Accuracy : 84.480000\n",
      "-----------------------------------------\n",
      "Round : 4500 | Train Accuracy : 86.900000\n",
      "Round : 4500 | Valid Accuracy : 83.650000\n",
      "Round : 4500 | Test Accuracy : 84.570000\n",
      "-----------------------------------------\n",
      "Round : 4550 | Train Accuracy : 86.945238\n",
      "Round : 4550 | Valid Accuracy : 83.661111\n",
      "Round : 4550 | Test Accuracy : 84.540000\n",
      "-----------------------------------------\n",
      "Round : 4600 | Train Accuracy : 86.890476\n",
      "Round : 4600 | Valid Accuracy : 83.627778\n",
      "Round : 4600 | Test Accuracy : 84.520000\n",
      "-----------------------------------------\n",
      "Round : 4650 | Train Accuracy : 86.935714\n",
      "Round : 4650 | Valid Accuracy : 83.683333\n",
      "Round : 4650 | Test Accuracy : 84.590000\n",
      "-----------------------------------------\n",
      "Round : 4700 | Train Accuracy : 86.902381\n",
      "Round : 4700 | Valid Accuracy : 83.638889\n",
      "Round : 4700 | Test Accuracy : 84.530000\n",
      "-----------------------------------------\n",
      "Round : 4750 | Train Accuracy : 86.811905\n",
      "Round : 4750 | Valid Accuracy : 83.638889\n",
      "Round : 4750 | Test Accuracy : 84.580000\n",
      "-----------------------------------------\n",
      "Round : 4800 | Train Accuracy : 86.911905\n",
      "Round : 4800 | Valid Accuracy : 83.650000\n",
      "Round : 4800 | Test Accuracy : 84.480000\n",
      "-----------------------------------------\n",
      "Round : 4850 | Train Accuracy : 86.995238\n",
      "Round : 4850 | Valid Accuracy : 83.666667\n",
      "Round : 4850 | Test Accuracy : 84.610000\n",
      "-----------------------------------------\n",
      "Round : 4900 | Train Accuracy : 86.990476\n",
      "Round : 4900 | Valid Accuracy : 83.694444\n",
      "Round : 4900 | Test Accuracy : 84.550000\n",
      "-----------------------------------------\n",
      "Round : 4950 | Train Accuracy : 87.004762\n",
      "Round : 4950 | Valid Accuracy : 83.722222\n",
      "Round : 4950 | Test Accuracy : 84.520000\n",
      "-----------------------------------------\n",
      "Round : 5000 | Train Accuracy : 86.780952\n",
      "Round : 5000 | Valid Accuracy : 83.694444\n",
      "Round : 5000 | Test Accuracy : 84.500000\n",
      "-----------------------------------------\n",
      "decay!!...........\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = params['W1'], params['b1']\n",
    "W2, b2 = params['W2'], params['b2']\n",
    "W3, b3 = params['W3'], params['b3']\n",
    "W4, b4 = params['W4'], params['b4']\n",
    "validAccArray = np.empty((0,18000),float)\n",
    "trainAccArray = np.empty((0,42000),float)\n",
    "testAccArray = np.empty((0,10000),float)\n",
    "for iternum in range(iteration):\n",
    "    vcorrect = []\n",
    "    tcorrect = []\n",
    "    ttcorrect = []\n",
    "    \n",
    "    # Forward-propagation\n",
    "    a1 = InnerProduct_ForProp(training_image,W1,b1)\n",
    "    z1 = Rectified_ForProp(a1)\n",
    "    a2 = InnerProduct_ForProp(z1,W2,b2)\n",
    "    z2 = Rectified_ForProp(a2)\n",
    "    a3 = InnerProduct_ForProp(z2,W3,b3)\n",
    "    z3 = Sigmoid_ForProp(a3)\n",
    "    a4 = InnerProduct_ForProp(z3,W4,b4)\n",
    "    out = Softmax_ForProp(a4)\n",
    "    \n",
    "    # Bakcward-propagation\n",
    "    dEda4 = Softmax_BackProp(out,training_label)\n",
    "    dEz3,dEW4,dEb4 = InnerProduct_BackProp(dEda4,z3,W4,b4)\n",
    "    dEda3 = Sigmoid_BackProp(dEz3,z3)\n",
    "    dEz2,dEW3,dEb3 = InnerProduct_BackProp(dEda3,z2,W3,b3)\n",
    "    dEda2 = Rectified_BackProp(dEz2,z2)\n",
    "    dEz1,dEW2,dEb2 = InnerProduct_BackProp(dEda2,z1,W2,b2)\n",
    "    dEda1 =  Rectified_BackProp(dEz1,z1)\n",
    "    dEz0,dEW1,dEb1 = InnerProduct_BackProp(dEda1,training_image,W1,b1)\n",
    "    \n",
    "    # Parameters Updating (Gradient descent)\n",
    "    \n",
    "    W1 = W1 - eta*dEW1\n",
    "    W2 = W2 - eta*dEW2\n",
    "    W3 = W3 - eta*dEW3\n",
    "    W4 = W4 - eta*dEW4\n",
    "    b1 = b1 - eta*dEb1\n",
    "    b2 = b2 - eta*dEb2\n",
    "    b3 = b3 - eta*dEb3\n",
    "    b4 = b4 - eta*dEb4\n",
    "    \n",
    "    # Do cross-validation to evaluate model\n",
    "    \n",
    "    z3 = InnerProduct_ForProp(training_image,W1,b1)\n",
    "    a3 = Rectified_ForProp(z3)\n",
    "    z4 = InnerProduct_ForProp(a3,W2,b2)\n",
    "    a4 = Rectified_ForProp(z4)\n",
    "    z5 = InnerProduct_ForProp(a4,W3,b3)\n",
    "    a5 = Sigmoid_ForProp(z5)\n",
    "    z6 = InnerProduct_ForProp(a5,W4,b4)\n",
    "    trainPrediction = Softmax_ForProp(z6)\n",
    "    \n",
    "    z7 = InnerProduct_ForProp(validating_image,W1,b1)\n",
    "    a6 = Rectified_ForProp(z7)\n",
    "    z8 = InnerProduct_ForProp(a6,W2,b2)\n",
    "    a7 = Rectified_ForProp(z8)\n",
    "    z9 = InnerProduct_ForProp(a7,W3,b3)\n",
    "    a8 = Sigmoid_ForProp(z9)\n",
    "    z10= InnerProduct_ForProp(a8,W4,b4)\n",
    "    validPrediction = Softmax_ForProp(z10)\n",
    "    \n",
    "    z7 = InnerProduct_ForProp(testing_image,W1,b1)\n",
    "    a6 = Rectified_ForProp(z7)\n",
    "    z8 = InnerProduct_ForProp(a6,W2,b2)\n",
    "    a7 = Rectified_ForProp(z8)\n",
    "    z9 = InnerProduct_ForProp(a7,W3,b3)\n",
    "    a8 = Sigmoid_ForProp(z9)\n",
    "    z10= InnerProduct_ForProp(a8,W4,b4)\n",
    "    testPrediction = Softmax_ForProp(z10)\n",
    "    \n",
    "    #print (Prediction[0])\n",
    "    #print np.max(Prediction[0])\n",
    "    #print np.argmax((Prediction[0]))\n",
    "    #print (validating_label[0])\n",
    "    #print np.argmax(validating_label[0])\n",
    "     \n",
    "   \n",
    "    tcorrect = [1 if a==b else 0 for (a,b) in zip(np.argmax(trainPrediction,axis=1),np.argmax(training_label,axis=1))]  \n",
    "    trainAccArray = np.append(trainAccArray, float(np.sum(tcorrect))/42000*100)\n",
    "    #print tAccuracy\n",
    "   \n",
    "    vcorrect = [1 if a==b else 0 for (a,b) in zip(np.argmax(validPrediction,axis=1),np.argmax(validating_label,axis=1))] \n",
    "    validAccArray = np.append(validAccArray, float(np.sum(vcorrect))/18000*100)\n",
    "  \n",
    "    ttcorrect = [1 if a==b else 0 for (a,b) in zip(np.argmax(testPrediction,axis=1),np.argmax(testing_label,axis=1))]  \n",
    "    testAccArray = np.append(testAccArray, float(np.sum(ttcorrect))/10000*100)\n",
    "    \n",
    "    if iternum%50 ==0:\n",
    "        print  \"Round : %d | Train Accuracy : %f\"%(iternum, trainAccArray[iternum])\n",
    "        print  \"Round : %d | Valid Accuracy : %f\"%(iternum, validAccArray[iternum])\n",
    "        print  \"Round : %d | Test Accuracy : %f\"%(iternum, testAccArray[iternum])\n",
    "        print\"-----------------------------------------\"\n",
    "    if  iternum!=0 and iternum%1000==0:\n",
    "        print \"decay!!...........\"\n",
    "        eta = eta * (decay_rate**(iternum/1000))\n",
    "        #print eta  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot iter accuracy curve and store accuracy in txt\n",
    "** Print out accuracy of test, train, valid set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using test_images and test_labels to do the final test\n",
    "#Using test_images and test_labels to do the final test\n",
    "np.savetxt(\"../project1/accuracy_txt/nn-trainacc.txt\", trainAccArray , fmt=\"%f\")\n",
    "np.savetxt(\"../project1/accuracy_txt/nn-validacc.txt\", validAccArray , fmt=\"%f\")\n",
    "np.savetxt(\"../project1/accuracy_txt/nn-testacc.txt\", validAccArray , fmt=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Max Train ACC : 87.038095\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+/+dDeIpqcGjNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104fdc690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Max Valid ACC : 83.766667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt4VdW57/Hvm5AASQgJIYHINYiCCFZxgy2tGgUVLxU9\nii2UgtWe3aftEbXbY1F3a1oftexuFVu3nvapKFspRetBrUqhigvraUEQUERFBZGAEu5oiJDLes8f\nmYQEclkJ6xJWfp/nycOcY805xjuHrjcjY97M3RERkeSVkugAREQktpToRUSSnBK9iEiSU6IXEUly\nSvQiIklOiV5EJMlFlOjN7EYzWxv8TA/Kcs1ssZmtN7NFZtY9tqGKiEhbtJjozexU4HrgX4DTgcvM\nbDAwA3jZ3YcAS4DbYhmoiIi0TSQj+lOAZe5+0N1rgNeAK4HLgTnBNnOAK2ITooiIHItIEv07wDnB\nVE0GcAnQD+jl7mUA7r4NyI9dmCIi0ladWtrA3d83s5nAy8AXwBqgOtaBiYhIdLSY6AHc/THgMQAz\nuxsoBcrMrJe7l5lZb2B7Y/uamR6mIyLSBu5u0agn0qtu8oN/+1M7Pz8PeB64NthkGvBcU/u7u37c\nufPOOxMeQ3v5UV+oL9QXzf9EU0QjeuAZM+sBVAE/cvd9wXTOU2Z2HbAZmBjVyEREJCoinbo5p5Gy\n3cC4qEckIiJRpTtj46i4uDjRIbQb6ovD1BeHqS9iw6I9F3RUA2Ye6zZERJKNmeHxPBkrIiLHLyV6\nEZEkp0QvIpLklOhFRJKcEr2ISJJTohcRSXJK9CIiSS7SRyCIiDQr7GFSrHbsWBOuITUlte4zdyfs\nYQ7WHKSyppLKcCWGsfvAbgbnDGZf5T72V+0no1MGVeEqwh7GMNJS03h7x9tUhivZ9eUuDtYc5OqT\nr6Zsfxmh0hCrtq9izfY1nJx7MgCrtq/iB6f9gDN7nclbO97io70fMSR3CCflnkSoNETPrj353du/\nq4vrzF5n8mbZm/To0oMB2QNYvX01fbL6ANAroxcFGQV0S+/GVwu/yr8t/TcArh9+PZ+Wf8qX1V9y\nTr9zKNtfRp+sPvz8Hz8np3MOew/uBaBzamcmnjyRTZ9v4pPPP+FbQ77FPz/9J/ur9tOlUxeWfbYM\ngB5derD7wG5GFoxk1fZVMflvoxumRBIg7GHcnRRLwazhPTE14Rp2fLmD9NR0uqV1A4OqmipKvyhl\n3a51LNq0iPd2vcflJ17O9ortFHUv4uG3Hk7QkUisvHPtO1G7YUqJXjokd8fMCHuYtTvX0rNrTzpZ\nJ1JTUtn15S4y0jLYtG8TO7/cSbVX82bZm7y48cVEhy0dSDQTvaZupN2oDlez+YvNFHQtYN2udQzO\nGUx5VTlbv9hKRXUFdy27i90Hdic6TJHjjkb0ElXb9m+jvLKcnl17EibMb1b9hp1f7mTplqWJDk3i\naFjeMAoyCgiVhurKTss/jR+c9gMqqiuYvXY2p+WfRlpKGgUZBWwt38pJOSdxzZBrjprKqu+z8s/I\nSs8iMy2TsIfZsHcDfbv1pTpcTUVVBVnpWdSEawgTJi0lja6dupJqqZgZ1eFqyivLOVhzkLyueaRY\nCnsO7CHsYfIzat+Eeugvvfqqw9V0Smk4Jq6/XVW4ik7Wqe4vxKbOU7TGtv3bKMwq1NSNxEdNuIYD\nNQfoktqFD/Z8wGPvPMbCTQsTHVbSGdV7FL0zerPn4B4O1hykoqqCCYMnMKj7IKrD1RR1L2LplqUU\nZBQwJHcIFdUV5HTOoVt6N2rCNWSkZbDv4D6y0rLolNIJx+sSjhyfovlQMyX6DqomXEOKpVAVruKh\nNQ/x1PqnOFhzkOpwx3wd8Pn9zmdJ6RIAstOz6d+tP98f8X16Z/Zmf9V+UlNSSbVUCjMLye6cjWEc\nrDlIVlpWm0dtIs2Je6I3s5uB64EwsBb4HnAC8CcgF1gFfNfdj8oSSvSJUxOuYe3Otdz62q18tv+z\nRIfTJtcNv45XS1/ljrPuIKdzTt2leD269ABg38F9ZKRl4O6kp6YnOFqR6IlrojezE4DXgaHuXmlm\n84GXgEuAP7v702b2CLDG3X/XyP5K9DG0ce9GVpat5PF1j1P6RWmiwznK2X3OZtyAcYzqPYrOqZ3Z\n+eVOBmQPIDMtM9GhibRr0Uz0kV51kwpkmlkY6Ap8CpwHTAo+nwOUAEclejk2VeEqtu3fxpLNS3h4\nzcNUVFckNJ5+3foxfuB4Tu15Kuf0OYfUlFQqayrp0qlLRPsXZBTEOEIROVKLid7dPzWz+6h9AXgF\nsJjaqZq97h4ONttC7VSOtMHBmoNU1VTxeeXnXPTMRQmJ4YrBVzB12FQG5wxu9qqHxkSa5EUkMVpM\n9GaWA0wABgD7gKeBixvZtMn5mZKSkrrl4uLiDv9eyH0H93Fz6GZWbFsRl/Z6dOnBdcOvY9yAcaSQ\nQmFWYVzaFZHIhUIhQqFQTOqOZI7+auAid/+fwfp3ga8BVwO93T1sZl8F7nT3o34BdPQ5+gPVB7hr\n2V08v+H5mLVx6aBLOTn3ZL6S/xWG9xxOekp6q0flItK+xHuOfjPwVTPrAhwExgIrgDxgIjAfmAY8\nF42Ajmfuzr6D+5jw3ISY3MH5yzG/pDCrkLN6n6VELiIRi/TyyjuBbwNVwGrg+0BfDl9euRqY4u5V\njeybtCP66nA1f/vkb9z62q1RqS8zLZPfnv9bzux1pm52EengdMNUAn1R+QVj5o2JSl2zL5rNyIKR\nuuFGRI6SiMsrOyx3591d7/LtF799TPW8es2r5HXJ05SLiMSdEn0j3J07Xr+Dv2z8S5v2v2jgRVx1\n0lV8Jf8rZKRlRDk6EZHWUaIPbC3fyvhnxrd5/3mXzmN4z+FRjEhEJDqU6IEfv/JjXtvyWqv2+e35\nv+XcvudqKkZE2r0OnehXla1i2l+nRbTtPd+4h7H9x2oqRkSOOx0y0T+46kH+sPYPLW43Y/QMvnPK\nd+IQkYhI7HSoRP/altf48Ss/bnG7t6a+pevYRSRpdIhEv3HfRiY8O6HZbUYWjGTOxXPiFJGISPwk\nfaIfMWdEs593Tu3Myikr4xSNiEj8JW2iX797PVf/5eomP5959kwuGXRJHCMSEUmMpEv0B6oPMGru\nqGa3WTllJZ1TO8cpIhGRxEqqRH/P8nuY9/68Jj9/9ZpX6dm1ZxwjEhFJvKS5tOSxdx5rMsmf2/dc\n3p76tpK8iHRISTGin/f+PO5/8/5GP3t76tu6e1VEOrTjPtE3dVXN699+ne6du8c5GhGR9ue4TvSN\nJfn8rvksuWZJAqIREWmfWpyjN7OTzWy1ma0K/t1nZtPNLNfMFpvZejNbZGZxHT6fNfesRsuV5EVE\nGmox0bv7B+5+hruPBM4E9gMLgBnAy+4+BFgC3BbTSOu5ZektVFRXNCjLSsti7bS18QpBROS40dqr\nbsYBG9y9FJgAHHpmwBzgimgG1pR5789j0aZFDcrGnDCGf07+ZzyaFxE57rTqnbFm9iiw0t0fMbM9\n7p5b77Nd7p7XyD5Re2fs2h1rmfzS5KPLNZIXkSSTkHfGmlkacDnw06Ao4uxdUlJSt1xcXExxcXGk\nu9Zx90aT/FtT32p1XSIi7U0oFCIUCsWk7ohH9GZ2OfAjdx8frL8HFLt7mZn1Bl5191Ma2S8qI/rG\nrrDRSF5EklU0R/StmaOfBNS/9fR54NpgeRrwXDQCakzpF6VHlWkkLyISmYhG9GbWFdgMDHL3L4Ky\nHsBTQL/gs4nuvreRfY9pRO/unPbfpzUou+vrd3HF4Lic+xURSYhojuhbdTK2TQ0cY6K/6vmr+GDP\nBw3KNGUjIskuUVM3cffSxpeOSvKrpqxKUDQiIsendjuib2zKZtFVizgh64RohSYi0m51iBH9kUke\nUJIXEWmDdpnoH3vnsaPKVnxnRQIiERE5/rW7RF8Trjnq2fJzL5lLl05dEhSRiMjxrd0l+sbeEnVa\n/tHTOCIiEpl2dTK2sqaSM588s0HZ4qsWU5hVGIvQRETaraQ9GXtkkn/hyheU5EVEjlG7SvRHGpA9\nINEhiIgc99pNov/Hp/9osP7rc3+doEhERJJLu5mjP/LplHrMgYh0ZEk3R79t/7YG6zeccUOCIhER\nST7tYkR/1tyzGrwD9s0pb5Kemh7TuERE2rOkG9Ef+aJvJXkRkehJeKKP9V8UIiIdXcIT/ZF3wj79\nzacTFImISHKKKNGbWXcze9rM3jOzdWZ2lpnlmtliM1tvZovMrHtbArj3jXsbrA/tMbQt1YiISBMi\nHdE/CLwUvPz7K8D7wAzgZXcfAiwBbmtt419Wf9lgPa9LXmurEBGRFrSY6M2sG3C2uz8G4O7V7r4P\nmADMCTabA7T6Ja6ryhq+Leql//FSa6sQEZEWRDKiHwTsNLPHzGyVmf3ezDKAXu5eBuDu24D81jb+\n8JqH65aH9hhKRlpGa6sQEZEWdIpwm5HAj919pZk9QO20TcSXy5SUlNQtFxcXU1xcjLvz0d6P6sqn\nDpsaaXUiIkknFAoRCoViUneLN0yZWS/gn+4+KFj/BrWJ/kSg2N3LzKw38Gowh3/k/o3eMLVx30Ym\nPDuhbn3Z5GVkpmUey7GIiCSNuN4wFUzPlJrZyUHRWGAd8DxwbVA2DXiuNQ2v+OzwqwHP73e+kryI\nSIxEMnUDMB2Ya2ZpwEbge0Aq8JSZXQdsBia2puE3tr1Rtzyq96jW7CoiIq0QUaJ397eAxrLxuLY0\n6u6sLFtZt65ELyISOwm5M3bD3g3sPrAbgJzOOZyUe1IiwhAR6RASkuhXlB2en/+XXv9CiiX8SQwi\nIkkrIRl2/vvz65bPKDgjESGIiHQYiZm62behbnlQzqBEhCAi0mHEPdEfmps/ZGTByHiHICLSocQ9\n0c9ZN6fBuh57ICISW3FP9LPfmR3vJkVEOrSEXu4yfuD4RDYvItIhxDXRhz3cYP32s26PZ/MiIh1S\nXBP9hr0bGqzndsmNZ/MiIh1SXBP9Mx8+E8/mRESEOCf63M6HR/BdO3WNZ9MiIh1WXBP9toptdcs/\n/MoP49m0iEiHFddEv27nurrlYXnD4tm0iEiHFbdEXx2ubnAydmiPofFqWkSkQ4voefRmtgnYB4SB\nKncfbWa5wHxgALAJuMbd9zVVx+YvNlMZrgSgV0YvunfufmyRi4hIRCId0YepfT/sGe4+OiibAbzs\n7kOAJcBtzVWw+fPNdctF3YvaEKqIiLRFpIneGtl2AnDowTVzgCuaq+Cz/Z/VLffJ6hNhsyIicqwi\nTfQOLDKzFWb2/aCsV/DicNx9G5DfXAX1E33vzN5tCFVERNoi0peDj3H3bWaWDyw2s/XUJv+Ifbzv\n47rlft36tWZXERE5BpG+HHxb8O8OM3sWGA2UmVkvdy8zs97A9qb2Lykp4eX1L7Pry11kDs1kwKUD\nohK8iEiyCIVChEKhmNRt7s0PzM0sA0hx93IzywQWA78AxgK73X2mmf0UyHX3GY3s7+7OiDkj6sqW\nfmspPbr0iOZxiIgkFTPD3S0adUUyou8FLDAzD7af6+6LzWwl8JSZXQdsBiY2VcGn5Z82WK//KAQR\nEYmtFhO9u38MnN5I+W5gXCSNbC3f2mDdLCq/pEREJAJxuTN2z4E9dcsn554cjyZFRCQQ90Q/oueI\nZrYUEZFoi0ui331gd92yTsKKiMRXXBL9zi931i3ndc2LR5MiIhKIS6Lf8eWOuuWeXXvGo0kREQnE\nfUSvRC8iEl9xH9EXdC2IR5MiIhKI/4g+QyN6EZF4ikuirw5XA5CZlqmXgouIxFlc3xmbnZ4dz+ZE\nRIQ4J/pu6d3i2ZyIiBDnRJ+VlhXP5kREhDgn+vyMZl9CJSIiMaA5ehGRJBffqZt0Td2IiMSb5uhF\nRJJcxInezFLMbJWZPR+sDzSzZWa23szmmVmLLzHJTMs8llhFRKQNWjOivxF4t976TOA+dx8C7AWu\nb6kCzdGLiMRfRInezPoClwB/qFd8PvBMsDwHuLKlenK76F2xIiLxFumI/gHgfwMOYGZ5wB53Dwef\nbwFOaKkSvRRcRCT+Wkz0ZnYpUObua4BDb/W2esuHeEt1de/cvdUBiojIsWnxBCrwdeByM7sE6Ap0\nA2YB3c0sJRjV9wU+baqCsgVlAPzXR//FRWMvori4+FjjFhFJKqFQiFAoFJO6zb3Fgfjhjc3OBf7N\n3S83s/nA/3X3+Wb2CPCWu/+fRvbx4Y8PB2DVd1eRlpIWpdBFRJKXmeHuR86ctMmxXEc/A/iJmX0A\n9AAebW7jTtZJSV5EJAEimbqp4+5LgaXB8sfAWZHu27lT59ZFJiIiURG3O2O7pHaJV1MiIlJP/BJ9\nJyV6EZFE0IheRCTJxS3Ra45eRCQxNKIXEUlymqMXEUlycUv0XTt1jVdTIiJSj0b0IiJJTnP0IiJJ\nLm6JPj01PV5NiYhIPfFL9ClK9CIiiRC3RJ+WqgeaiYgkgkb0IiJJTiN6EZEkF79Er2fRi4gkhBK9\niEiSi+Tl4J3NbLmZrTaztWZ2Z1A+0MyWmdl6M5tnZs2+xERTNyIiidFionf3g8B57n4GcDpwsZmd\nBcwE7nP3IcBe4Prm6tHJWBGRxIho6sbdK4LFztS+ftCB84BngvI5wJXN1aGpGxGRxIgo0ZtZipmt\nBrYBfwM2AHvdPRxssgU4obk6dGesiEhiRPRy8CChn2Fm2cAC4JTGNmtq/7IFZTy55kle7/46xcXF\nFBcXtylYEZFkFQqFCIVCManb3JvMz43vYPZzoAK4Fejt7mEz+ypwp7tf3Mj2Pvzx4fxu3O8Y02dM\nVIIWEUl2Zoa7WzTqiuSqm55m1j1Y7gqMA94FXgUmBptNA55rrh5ddSMikhiRTN0UAnPMLIXaXwzz\n3f0lM3sP+JOZ3QWsBh5trhKdjBURSYwWE727rwVGNlL+MXBWpA3pZKyISGLozlgRkSSnF4+IiCQ5\njehFRJKcEr2ISJLT1I2ISJLTiF5EJMnpDVMiIkkubom+U/OPqxcRkRiJS6JPT0nHLCqPbBARkVaK\nS6LXtI2ISOLEJ9HrRKyISMLEbepGREQSQ1M3IiJJTlM3IiJJTiN6EZEkpzl6EZEkF8mrBPua2RIz\ne9fM1prZ9KA818wWm9l6M1t06HWDjdHUjYhI4kQyoq8GfuLuw4CvAT82s6HADOBldx8CLAFua6oC\nTd2IiCROi4ne3be5+5pguRx4D+gLTADmBJvNAa5oqg6N6EVEEqdVc/RmNhA4HVgG9HL3Mqj9ZQDk\nN7VfqqW2PUIRETkmET9pzMyygD8DN7p7uZl5pPuufGIlJa+XAFBcXExxcXHrohQRSXKhUIhQKBST\nus295XxtZp2AF4CF7v5gUPYeUOzuZWbWG3jV3U9pZF+/aclNPHDeA1EOXUQkeZkZ7h6Vp0FGOnUz\nG3j3UJIPPA9cGyxPA55raufUFE3diIgkSotTN2b2deA7wFozWw04cDswE3jKzK4DNgMTm6pDc/Qi\nIonTYqJ39/8HNJWpx0XSiBK9iEjixOXOWE3diIgkTnwSvUb0IiIJE5dE3ylF74sVEUkUjehFRJKc\n5uhFRJJcfKZuTFM3IiKJEpcMnGJx+X0irTBw4EA++eSTRIch7cCAAQPYtGlTosOQGIpLotfUTfvz\nySefEMnjLyT5mUXlLntpxzR1IyLMmjWLuXPnJjoMiRGdjBURCgoK2LFjR6LDkBjR5ZUiIklON0yJ\niCQ5jeglaSxdupR+/frVrQ8fPpzXXnstom1Fkpkur5SkUv8KknfeeSfibUWSmaZuRNqhmpqaRIcg\nSURTN9LuzJw5k4kTG77H5qabbuKmm27i8ccfZ9iwYWRnZzN48GB+//vfN1lPUVERS5YsAeDAgQNc\ne+219OjRg+HDh7NixYpmY1ixYgVjxowhNzeXPn36cMMNN1BdXV33+bp167jwwgvJy8ujsLCQX/3q\nVwCEw2HuueceBg8eTHZ2NqNGjWLr1q188sknpKSkEA6H6+o477zzmD17NgBz5szhG9/4Bj/5yU/I\ny8vjF7/4BRs3bmTs2LH07NmTgoICpkyZwueff163/5YtW7jqqqsoKCggPz+f6dOnU1lZSV5eHuvW\nravbbseOHWRkZLBr166Wul6SVCRvmHoUuAwoc/fTgrJcYD4wANgEXOPu+5qqQ5dXHl9GzBkR1frW\nTlvbqu0nTZrEXXfdRXl5OVlZWYTDYZ566imeffZZdu3axYsvvkhRURF///vfGT9+PKNHj+b0009v\nts6SkhI+/vhjPv74Y8rLyxk/fnyz26empjJr1ixGjRpFaWkpF198MQ8//DDTp0+nvLycCy64gFtv\nvZUXXniBqqoq3n33XQDuu+8+5s+fz1//+lcGDx7M2rVrycjI4PPPP29xqmj58uVMnjyZHTt2UFVV\nxZYtW7j99ts599xz2bdvH1dddRUlJSXcf//9hMNhLrvsMsaNG8fcuXNJSUlh5cqVpKenM2nSJJ58\n8knuvfdeAObNm8cFF1xAXl5eK/4rSDKJZET/GHDREWUzgJfdfQiwBLituQo0opfW6N+/PyNHjuTZ\nZ58F4JVXXiEzM5PRo0dz8cUXU1RUBMDZZ5/NhRdeyN///vcW63z66af593//d7p3706fPn2YPn16\ns9uPHDmS0aNHY2b079+ff/3Xf2Xp0qUAvPDCCxQWFnLTTTeRnp5OZmYmo0aNAuDRRx/l7rvvZvDg\nwQCMGDGC3NzciI67T58+/OhHPyIlJYXOnTtz4oknMnbsWDp16kReXh4333xzXQzLly/ns88+4z/+\n4z/o0qUL6enpjBkzBoCpU6c2uPnpiSee4Lvf/W5EMUhyajHRu/vrwJ4jiicAc4LlOcAVzdWhOXpp\nrUmTJjFv3jygdkQ6efJkABYuXMjXvvY18vLyyM3NZeHChezcubPF+j799FP69u1btz5gwIC65T/+\n8Y9069aN7OxsLr30UgA+/PBDvvnNb1JYWEhOTg533HFHXTulpaWceOKJjbZTWlrKoEGD2nTMR14F\ntGPHDiZNmkTfvn3JyclhypQpdTFs2bKFAQMGkJJy9Fd49OjRZGVlsXTpUtavX8+GDRu4/PLL2xST\nJIe2ZuACdy8DcPdtZpbf3Ma66ub40tqplliYOHEit9xyC1u3bmXBggUsX76cyspKrr76ap588kkm\nTJhASkoKV155ZUTP7CksLKS0tJRTTjkFoMED3SZPnlz3i+SQH/7wh4wcOZL58+eTkZHBgw8+yDPP\nPAPUJuRDv4SO1L9/fzZs2MCwYcMalGdmZgJQUVFBVlYWANu2bWuwzZFTO7fddhspKSm888475OTk\n8Nxzz3HDDTfUxbB582bC4XCjyX7atGk88cQT9O7dm6uvvpr09PTmO0iSWlwy8NxZcykpKaGkpIRQ\nKBSPJuU417NnT84991y+973vMWjQIE4++WQqKyuprKykZ8+epKSksHDhQhYvXhxRfddccw333nsv\ne/fuZcuWLTz00EPNbv/FF1+QnZ1NRkYG77//Po888kjdZ5dddhllZWX85je/obKykvLyct544w0A\nrr/+en72s5/x0UcfAbB27Vr27NlDz5496dOnD08++SThcJjZs2ezYcOGFmPIysoiOzubrVu38utf\n/7rus9GjR1NYWMiMGTOoqKjg4MGD/OMf/6j7fMqUKSxYsIC5c+cyderUiPpIEisUCtXlyZKSkuhW\n7u4t/lB70vXteuvvAb2C5d7Ae83s6x/s/sClfan9T9++PfHEE56SkuL33XdfXdnDDz/svXr18tzc\nXJ86dapPmjTJf/azn7m7eygU8n79+tVtW1RU5K+88oq7u1dUVPjUqVM9JyfHTz31VP/P//zPBtse\n6bXXXvOhQ4d6t27d/JxzzvE777zTzz777LrP161b52PHjvXc3FwvLCz0mTNnurt7TU2N33333V5U\nVOTZ2dk+evRo37p1q7u7L1y40IuKijw3N9dvueUWLy4u9kcffdTd3R9//PEG9R9q48wzz/Ru3br5\nGWec4ffff3+DmEtLS/2KK67wvLw8z8/P9xtvvLHB/uPGjfOioqIW+xnwuXPn+gMPPNDithI/wXc0\nohzd0o95BH/2mtlA4C/uPiJYnwnsdveZZvZTINfdZzSxr0fShsSXmekxxUnu+uuvp0+fPvzyl79s\ndjszY+7cuWzfvp2bbropTtFJS4LvaFTu6ovk8so/AsVAnpltBu4EfgU8bWbXAZuBiU3XICLxtmnT\nJhYsWMDq1asTHYq0Ay0menef3MRH46Ici4hEwc9//nNmzZrF7bff3uDqIum4Ipq6OaYGNHXTLmnq\nRg7R1E37FM2pG133KCKS5JToRUSSnBK9iEiS07MJOqgBAwboeewCQK9evRIdgsSYEn0HtWnTJgBm\nzZpFQUFBYoMRkZhSou/g8vPz2b59e6LDkHYgP7/ZR1bJcUyXV4qItEO6vFJERCKmRC8ikuSU6EVE\nkpwSvYhIklOiFxFJckr0IiJJToleRCTJHVOiN7PxZva+mX0QvGlKRETamTYnejNLAR4CLgJOBSaZ\n2dBoBZaM9GL0w9QXh6kvDlNfxMaxjOhHAx+6+yfuXgX8CZgQnbCSk/4nPkx9cZj64jD1RWwcS6Lv\nA5TWW98SlImISDtyLIm+sWcw6KE2IiLtTJsfamZmXwVK3H18sD4DcHefecR2Sv4iIm0QrYeaHUui\nTwXWA2OBz4A3gEnu/l40AhMRkeho8/Po3b3GzP4XsJjaKaBHleRFRNqfmD+PXkREEitmd8Z2hJup\nzOxRMyszs7frleWa2WIzW29mi8yse73PfmNmH5rZGjM7vV75tKCf1pvZ1HgfRzSYWV8zW2Jm75rZ\nWjObHpR3uP4ws85mttzMVgd9cWdQPtDMlgXHNc/MOgXl6Wb2p6Av/mlm/evVdVtQ/p6ZXZioYzpW\nZpZiZqvM7PlgvUP2hZltMrO3gv833gjKYv8dcfeo/1D7C+QjYACQBqwBhsairUT+AN8ATgferlc2\nE7g1WP4p8Ktg+WLgxWD5LGBZsJwLbAC6AzmHlhN9bG3oi97A6cFyFrXnb4Z24P7ICP5NBZYFxzgf\nmBiUPwJiEI1gAAADPUlEQVT8IFj+IfBwsPwt4E/B8jBgNbVTrAOD75Ql+tja2B83A08CzwfrHbIv\ngI1A7hFlMf+OxGpE3yFupnL314E9RxRPAOYEy3M4fNwTgP8O9lsOdDezXtTeWbzY3fe5+15qz3mM\nj3Xs0ebu29x9TbBcDrwH9KXj9kdFsNiZ2uTkwHnAM0H5HOCKYLl+H/0ZOD9YvpzaRFft7puAD6n9\nbh1XzKwvcAnwh3rF59MB+4Lay9KPzLsx/47EKtF35JupCty9DGqTH1AQlDfVJ0eWb+U47yszG0jt\nXzrLgF4dsT+CqYrVwDbgb9SOuva6ezjYpP53ou6Y3b0G2GdmPUiSvgAeAP43wX02ZpYH7OmgfeHA\nIjNbYWbfD8pi/h1p81U3LdDNVEc7sk+M2j5Jqr4ysyxqR2I3unt5M/dRJHV/BEnsDDPLBhYApzS2\nWfBvU8d83PeFmV0KlLn7GjMrPlTM0ceW9H0RGOPu28wsH1hsZutp+jii9h2J1Yh+C9C/3npf4NMY\ntdXelAV/XmFmvYHtQfkWoF+97Q71SdL0VXBC7c/AE+7+XFDcYfsDwN0/B5YCXwVygocBQsPjquuL\n4P6U7u6+h6b76HjydeByM9sIzKN2KmYWtdMQHa0vDo3YcfcdwLPUTj/F/DsSq0S/AhhsZgPMLB34\nNvB8jNpKtCNHJ88D1wbL1wLP1SufCnV3Fe8N/lxbBFxgZt3NLBe4ICg7Hs0G3nX3B+uVdbj+MLOe\nh66cMLOuwDjgXeBVYGKw2TQa9sW0YHkisKRe+beDK1GKgMHU3ph43HD32929v7sPojYPLHH3KXTA\nvjCzjOAvXswsE7gQWEs8viMxPLs8ntorLz4EZiT6bHeMjvGP1P4mPQhsBr5H7Rnxl4Nj/xuQU2/7\nh6i9WuAtYGS98muDfvoAmJro42pjX3wdqKH2CqvVwKrg/4EeHa0/gBHB8a8B3gbuCMqLgOXBcc0H\n0oLyzsBTwTEvAwbWq+u2oI/eAy5M9LEdY7+cy+GrbjpcXwTHfOj7sfZQXozHd0Q3TImIJDm9SlBE\nJMkp0YuIJDklehGRJKdELyKS5JToRUSSnBK9iEiSU6IXEUlySvQiIknu/wOzoRsAlap5ZgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10761bf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Max Test ACC : 83.766667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10857de10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot iter accuracy curve\n",
    "#Store your every iter number and accuracy in tow numpy array \"iter_log\" and \"accuracy_log\"\n",
    "#example\n",
    "train_data =  np.array([data.rstrip('\\n') for data in open('../project1/accuracy_txt/nn-trainacc.txt')]).astype(np.float)\n",
    "valid_data =  np.array([data.rstrip('\\n') for data in open('../project1/accuracy_txt/nn-validacc.txt')]).astype(np.float)\n",
    "test_data =  np.array([data.rstrip('\\n') for data in open('../project1/accuracy_txt/nn-testacc.txt')]).astype(np.float)\n",
    "print \"--------------------------------------------\"\n",
    "print \"Max Train ACC : %f\"%np.max(train_data)\n",
    "iter_log = np.empty((0,5001),int)\n",
    "accuracy_log = np.empty((0,5001),float)\n",
    "for i in range(0,5001):\n",
    "    iter_log = np.append(iter_log,i)\n",
    "accuracy_log = train_data\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(iter_log, accuracy_log, label='train-accuracy', color=\"#1f77b4\", linewidth=3)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.2),  shadow=True, ncol=2)\n",
    "plt.show()\n",
    "\n",
    "print \"--------------------------------------------\"\n",
    "print \"Max Valid ACC : %f\"%np.max(valid_data)\n",
    "iter_log = np.empty((0,5001),int)\n",
    "accuracy_log = np.empty((0,5001),float)\n",
    "for i in range(0,5001):\n",
    "    iter_log = np.append(iter_log,i)\n",
    "accuracy_log = valid_data\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(iter_log, accuracy_log, label='valid-accuracy', color=\"#2ca02c\", linewidth=3)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.2),  shadow=True, ncol=2)\n",
    "plt.show()\n",
    "\n",
    "print \"--------------------------------------------\"\n",
    "print \"Max Test ACC : %f\"%np.max(test_data)\n",
    "iter_log = np.empty((0,5001),int)\n",
    "accuracy_log = np.empty((0,5001),float)\n",
    "for i in range(0,5001):\n",
    "    iter_log = np.append(iter_log,i)\n",
    "accuracy_log = test_data\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(iter_log, accuracy_log, label='test-accuracy', color=\"#e377c2\", linewidth=3)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 0.2),  shadow=True, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
